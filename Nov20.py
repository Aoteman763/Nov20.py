import streamlit as st
import pandas as pd
import numpy as np
import json

st.set_page_config(page_title="LLM DSSç³»ç»Ÿ", page_icon="ğŸ¤–", layout="wide")

def create_sample_data(dataset_type):
    np.random.seed(42)

    if dataset_type == "é”€å”®æ•°æ®":
        dates = pd.date_range('2024-01-01', '2024-06-30', freq='D')
        data = {
            'æ—¥æœŸ': dates,
            'é”€å”®é¢': np.random.normal(10000, 2000, len(dates)).cumsum() + 100000,
            'å®¢æˆ·æ•°': np.random.poisson(50, len(dates)),
            'è½¬åŒ–ç‡': np.random.beta(5, 2, len(dates)),
            'å¹¿å‘Šæ”¯å‡º': np.random.normal(5000, 1000, len(dates))
        }
        df = pd.DataFrame(data)
        df['æœˆä»½'] = df['æ—¥æœŸ'].dt.month
        return df

    elif dataset_type == "å®¢æˆ·åˆ†ç±»":
        data = {
            'å¹´é¾„': np.random.normal(35, 10, 500),
            'æ”¶å…¥': np.random.normal(50000, 15000, 500),
            'æ¶ˆè´¹é¢‘ç‡': np.random.poisson(5, 500),
            'å¹³å‡è®¢å•ä»·å€¼': np.random.normal(200, 50, 500),
            'å®¢æˆ·ä»·å€¼': np.random.normal(1000, 300, 500)
        }
        df = pd.DataFrame(data)
        df['å®¢æˆ·ç±»å‹'] = np.where(df['å®¢æˆ·ä»·å€¼'] > 1200, 'é«˜ä»·å€¼',
                                  np.where(df['å®¢æˆ·ä»·å€¼'] > 800, 'ä¸­ä»·å€¼', 'ä½ä»·å€¼'))
        return df

    else:
        products = ['äº§å“A', 'äº§å“B', 'äº§å“C', 'äº§å“D', 'äº§å“E']
        data = {
            'äº§å“': np.random.choice(products, 200),
            'å¸‚åœºä»½é¢': np.random.beta(2, 5, 200) * 100,
            'å¢é•¿ç‡': np.random.normal(10, 5, 200),
            'å®¢æˆ·æ»¡æ„åº¦': np.random.normal(4.2, 0.5, 200),
            'ä»·æ ¼': np.random.normal(100, 20, 200)
        }
        df = pd.DataFrame(data)
        return df
def simple_predictor(df, target_column):
    """ç®€å•çš„è¶‹åŠ¿é¢„æµ‹"""
    if target_column in df.columns:
        values = df[target_column].values
        if len(values) > 1:
            last_value = values[-1]
            trend = (values[-1] - values[0]) / len(values) if len(values) > 1 else 0
            prediction = last_value + trend * 5
            return max(prediction, 0)
    return 0

def ai_analysis(dataset_type, insights, metrics):

    analysis_templates = {
        "é”€å”®æ•°æ®": f"""
## ğŸ“Š é”€å”®åˆ†ææŠ¥å‘Š

**å…³é”®æŒ‡æ ‡**:
- å¹³å‡é”€å”®é¢: Â¥{metrics.get('avg_sales', 0):,.0f}
- å®¢æˆ·è½¬åŒ–ç‡: {metrics.get('conversion_rate', 0):.1%}
- è¶‹åŠ¿æ–¹å‘: {'ä¸Šå‡' if metrics.get('trend', 0) > 0 else 'ä¸‹é™'}
### ğŸ” æ·±åº¦æ´å¯Ÿ:
{insights}

### ğŸ’¡ è¡ŒåŠ¨å»ºè®®:
1. **ä¼˜åŒ–è¥é”€ç­–ç•¥**: åŸºäºè½¬åŒ–ç‡æ•°æ®è°ƒæ•´å¹¿å‘ŠæŠ•æ”¾
2. **å®¢æˆ·ç»†åˆ†**: è¯†åˆ«é«˜ä»·å€¼å®¢æˆ·ç¾¤ä½“é‡ç‚¹ç»´æŠ¤
3. **å­£èŠ‚æ€§è°ƒæ•´**: æ ¹æ®é”€å”®è¶‹åŠ¿åˆ¶å®šåº“å­˜è®¡åˆ’
4. **æ¸ é“ä¼˜åŒ–**: åˆ†æå„é”€å”®æ¸ é“æ•ˆæœåˆ†é…èµ„æº
""",
        "å®¢æˆ·åˆ†ç±»": f"""
## ğŸ‘¥ å®¢æˆ·ä»·å€¼åˆ†æ
**åˆ†ç±»ç»“æœ**:
- é«˜ä»·å€¼å®¢æˆ·: {metrics.get('high_value_pct', 0):.1%}
- ä¸­ä»·å€¼å®¢æˆ·: {metrics.get('medium_value_pct', 0):.1%}
- ä½ä»·å€¼å®¢æˆ·: {metrics.get('low_value_pct', 0):.1%}

### ğŸ” å®¢æˆ·æ´å¯Ÿ:
{insights}
### ğŸ’¡ å®¢æˆ·ç­–ç•¥:
1. **ç²¾å‡†è¥é”€**: é’ˆå¯¹ä¸åŒä»·å€¼ç¾¤ä½“å®šåˆ¶è¥é”€æ–¹æ¡ˆ
2. **å¿ è¯šåº¦è®¡åˆ’**: æå‡é«˜ä»·å€¼å®¢æˆ·ç²˜æ€§
3. **ä»·å€¼æå‡**: è®¾è®¡ä¸­ä»·å€¼å®¢æˆ·å‡çº§è·¯å¾„
4. **æˆæœ¬ä¼˜åŒ–**: åˆç†åˆ†é…ä½ä»·å€¼å®¢æˆ·æœåŠ¡èµ„æº
""",
        "å¸‚åœºæ•°æ®": f"""
## ğŸ“ˆ å¸‚åœºç«äº‰åˆ†æ

**å¸‚åœºæ¦‚å†µ**:
- å¹³å‡å¸‚åœºä»½é¢: {metrics.get('avg_market_share', 0):.1f}%
- å¹³å‡å¢é•¿ç‡: {metrics.get('avg_growth', 0):.1f}%
- å®¢æˆ·æ»¡æ„åº¦: {metrics.get('avg_satisfaction', 0):.1f}/5
### ğŸ” å¸‚åœºæ´å¯Ÿ:
{insights}

### ğŸ’¡ ç«äº‰ç­–ç•¥:
1. **äº§å“å®šä½**: å¼ºåŒ–ä¼˜åŠ¿äº§å“å¸‚åœºåœ°ä½
2. **ä»·æ ¼ç­–ç•¥**: åŸºäºç«äº‰æ€åŠ¿è°ƒæ•´å®šä»·
3. **å®¢æˆ·ä½“éªŒ**: æå‡æ»¡æ„åº¦å¢å¼ºå®¢æˆ·å¿ è¯š
4. **åˆ›æ–°é©±åŠ¨**: æŠ•èµ„é«˜å¢é•¿æ½œåŠ›äº§å“
"""
    }

    return analysis_templates.get(dataset_type, "åˆ†ææŠ¥å‘Šç”Ÿæˆä¸­...")

def generate_insights(df, dataset_type):

    if dataset_type == "é”€å”®æ•°æ®":
        avg_sales = df['é”€å”®é¢'].mean()
        max_sales = df['é”€å”®é¢'].max()
        min_sales = df['é”€å”®é¢'].min()
        conversion_rate = df['è½¬åŒ–ç‡'].mean()

        insights = f"""
- é”€å”®é¢èŒƒå›´: Â¥{min_sales:,.0f} - Â¥{max_sales:,.0f}
- å¹³å‡è½¬åŒ–ç‡: {conversion_rate:.1%}ï¼Œæœ‰è¾ƒå¤§æå‡ç©ºé—´
- å»ºè®®é‡ç‚¹å…³æ³¨è½¬åŒ–ç‡ä¼˜åŒ–ï¼Œæ¯æå‡1%å¯å¢åŠ çº¦Â¥{avg_sales * 0.01:,.0f}æ”¶å…¥
"""
        metrics = {
            'avg_sales': avg_sales,
            'conversion_rate': conversion_rate,
            'trend': 1 if max_sales > avg_sales else -1
        }
    elif dataset_type == "å®¢æˆ·åˆ†ç±»":
        value_counts = df['å®¢æˆ·ç±»å‹'].value_counts(normalize=True)
        avg_income = df['æ”¶å…¥'].mean()
        avg_value = df['å®¢æˆ·ä»·å€¼'].mean()

        insights = f"""
- é«˜ä»·å€¼å®¢æˆ·å æ¯”: {value_counts.get('é«˜ä»·å€¼', 0):.1%}
- å¹³å‡å®¢æˆ·æ”¶å…¥: Â¥{avg_income:,.0f}
- å¹³å‡å®¢æˆ·ä»·å€¼: Â¥{avg_value:,.0f}
- å®¢æˆ·ä»·å€¼åˆ†å¸ƒæ˜¾ç¤ºæœ‰æ˜¾è‘—ç»†åˆ†æœºä¼š
"""
        metrics = {
            'high_value_pct': value_counts.get('é«˜ä»·å€¼', 0),
            'medium_value_pct': value_counts.get('ä¸­ä»·å€¼', 0),
            'low_value_pct': value_counts.get('ä½ä»·å€¼', 0)
        }
    else:
        avg_share = df['å¸‚åœºä»½é¢'].mean()
        avg_growth = df['å¢é•¿ç‡'].mean()
        avg_satisfaction = df['å®¢æˆ·æ»¡æ„åº¦'].mean()

        insights = f"""
- äº§å“å¹³å‡å¸‚åœºä»½é¢: {avg_share:.1f}%
- å¹³å‡å¢é•¿ç‡: {avg_growth:.1f}%
- å¹³å‡å®¢æˆ·æ»¡æ„åº¦: {avg_satisfaction:.1f}/5åˆ†
- å¸‚åœºå­˜åœ¨æ˜æ˜¾å·®å¼‚åŒ–æœºä¼š
"""
        metrics = {
            'avg_market_share': avg_share,
            'avg_growth': avg_growth,
            'avg_satisfaction': avg_satisfaction
        }

    return insights, metrics
def create_simple_chart(df, chart_type="line"):
    if chart_type == "line" and 'é”€å”®é¢' in df.columns and 'æ—¥æœŸ' in df.columns:
        recent_data = df.tail(10)
        max_val = recent_data['é”€å”®é¢'].max()
        min_val = recent_data['é”€å”®é¢'].min()
        chart = "é”€å”®é¢è¶‹åŠ¿å›¾:\n"
        for _, row in recent_data.iterrows():
            value = row['é”€å”®é¢']
            bar_length = int((value - min_val) / (max_val - min_val) * 50) if max_val > min_val else 25
            chart += f"{row['æ—¥æœŸ'].strftime('%m-%d')}: {'â–ˆ' * bar_length} Â¥{value:,.0f}\n"
        return chart

    elif chart_type == "bar" and 'äº§å“' in df.columns and 'å¸‚åœºä»½é¢' in df.columns:
        chart = "äº§å“å¸‚åœºä»½é¢:\n"
        for product in df['äº§å“'].unique():
            avg_share = df[df['äº§å“'] == product]['å¸‚åœºä»½é¢'].mean()
            bar_length = int(avg_share / 2)  # ç¼©æ”¾æ¯”ä¾‹
            chart += f"{product}: {'â–ˆ' * bar_length} {avg_share:.1f}%\n"
        return chart

    return "å›¾è¡¨æ•°æ®ä¸è¶³"

def main():
    st.title("ğŸ¤– åŸºäºLLMçš„å†³ç­–æ”¯æŒç³»ç»Ÿ")
    st.markdown("---")
    with st.sidebar:
        st.header("ç³»ç»Ÿé…ç½®")
        dataset_option = st.selectbox(
            "é€‰æ‹©æ•°æ®ç±»å‹",
            ["é”€å”®æ•°æ®", "å®¢æˆ·åˆ†ç±»", "å¸‚åœºæ•°æ®"]
        )
        analysis_dimension = st.selectbox(
            "åˆ†æç»´åº¦",
            ["è¶‹åŠ¿åˆ†æ", "åˆ†ç±»åˆ†æ", "å¯¹æ¯”åˆ†æ", "é¢„æµ‹åˆ†æ"]
        )
        if st.button("å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
            st.session_state.analyze = True
            st.session_state.dataset_type = dataset_option
    col1, col2 = st.columns([2, 1])
    with col1:
        st.subheader("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        df = create_sample_data(st.session_state.get('dataset_type', 'é”€å”®æ•°æ®'))
        col1_1, col1_2, col1_3 = st.columns(3)
        with col1_1:
            st.metric("æ•°æ®è®°å½•", len(df))
        with col1_2:
            st.metric("æ•°æ®ç»´åº¦", len(df.columns))
        with col1_3:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            st.metric("æ•°å€¼ç‰¹å¾", len(numeric_cols))
        with st.expander("æŸ¥çœ‹æ•°æ®", expanded=True):
            st.dataframe(df.head(10), use_container_width=True)
        with st.expander("æ•°æ®å¯è§†åŒ–"):
            if st.session_state.get('dataset_type') == "é”€å”®æ•°æ®":
                st.write("**é”€å”®é¢è¶‹åŠ¿:**")
                chart_text = create_simple_chart(df, "line")
                st.text(chart_text)
                st.write("**ç»Ÿè®¡æ‘˜è¦:**")
                st.write(f"æœ€å¤§å€¼: Â¥{df['é”€å”®é¢'].max():,.0f}")
                st.write(f"æœ€å°å€¼: Â¥{df['é”€å”®é¢'].min():,.0f}")
                st.write(f"å¹³å‡å€¼: Â¥{df['é”€å”®é¢'].mean():,.0f}")
            elif st.session_state.get('dataset_type') == "å®¢æˆ·åˆ†ç±»":
                st.write("**å®¢æˆ·ç±»å‹åˆ†å¸ƒ:**")
                type_counts = df['å®¢æˆ·ç±»å‹'].value_counts()
                for type_name, count in type_counts.items():
                    percentage = count / len(df) * 100
                    st.write(f"- {type_name}: {count}äºº ({percentage:.1f}%)")
            else:
                st.write("**äº§å“è¡¨ç°:**")
                chart_text = create_simple_chart(df, "bar")
                st.text(chart_text)
    with col2:
        st.subheader("ğŸ”® é¢„æµ‹åˆ†æ")
        if st.session_state.get('analyze', False):
            target_col = 'é”€å”®é¢' if st.session_state.dataset_type == 'é”€å”®æ•°æ®' else 'å®¢æˆ·ä»·å€¼'
            if target_col in df.columns:
                prediction = simple_predictor(df, target_col)
                current_avg = df[target_col].mean()
                st.metric(
                    "æœªæ¥é¢„æµ‹",
                    f"Â¥{prediction:,.0f}" if 'é”€å”®é¢' in target_col or 'ä»·å€¼' in target_col else f"{prediction:.1f}%",
                    delta=f"{((prediction - current_avg) / current_avg * 100):.1f}%"
                )
            st.write("**å…³é”®ç»Ÿè®¡:**")
            numeric_df = df.select_dtypes(include=[np.number])
            for col in list(numeric_df.columns)[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæ•°å€¼åˆ—
                mean_val = numeric_df[col].mean()
                st.write(f"- {col}: {mean_val:,.1f}")
            st.write("**æ•°æ®è´¨é‡:**")
            completeness = (1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
            st.write(f"- å®Œæ•´æ€§: {completeness:.1f}%")
            st.write(f"- å”¯ä¸€å€¼: {df.nunique().mean():.0f}ä¸ª")
    if st.session_state.get('analyze', False):
        st.markdown("---")
        st.subheader("ğŸ¤– AIæ™ºèƒ½åˆ†æ")
        insights, metrics = generate_insights(df, st.session_state.dataset_type)
        analysis_content = ai_analysis(st.session_state.dataset_type, insights, metrics)
        st.markdown(analysis_content)
        st.markdown("---")
        st.subheader("ğŸ’¬ æ™ºèƒ½é—®ç­”")
        question = st.text_input("å‘AIåŠ©æ‰‹æé—®:",
                                 placeholder="ä¾‹å¦‚ï¼šå¦‚ä½•æå‡é”€å”®é¢ï¼Ÿ")
        if question:
            qa_pairs = {
                "å¦‚ä½•æå‡é”€å”®é¢": "å»ºè®®ï¼š1.ä¼˜åŒ–äº§å“å®šä»· 2.åŠ å¼ºæ•°å­—è¥é”€ 3.æå‡å®¢æˆ·ä½“éªŒ 4.æ‹“å±•é”€å”®æ¸ é“",
                "æ€æ ·æé«˜è½¬åŒ–ç‡": "å»ºè®®ï¼š1.ä¼˜åŒ–è½åœ°é¡µè®¾è®¡ 2.ç®€åŒ–è´­ä¹°æµç¨‹ 3.æä¾›ä¸ªæ€§åŒ–æ¨è 4.åŠ å¼ºå®¢æˆ·ä¿¡ä»»å»ºè®¾",
                "å®¢æˆ·åˆ†ç±»ç­–ç•¥": "å»ºè®®ï¼š1.RFMæ¨¡å‹ç»†åˆ† 2.è¡Œä¸ºæ¨¡å¼åˆ†æ 3.ç”Ÿå‘½å‘¨æœŸç®¡ç† 4.ä¸ªæ€§åŒ–æœåŠ¡",
                "å¸‚åœºç«äº‰åˆ†æ": "å»ºè®®ï¼š1.SWOTåˆ†æ 2.ç«äº‰å¯¹æ‰‹ç›‘æ§ 3.å·®å¼‚åŒ–å®šä½ 4.åˆ›æ–°é©±åŠ¨",
                "æå‡å®¢æˆ·æ»¡æ„åº¦": "å»ºè®®ï¼š1.æ”¹è¿›äº§å“è´¨é‡ 2.ä¼˜åŒ–å®¢æˆ·æœåŠ¡ 3.æ”¶é›†ç”¨æˆ·åé¦ˆ 4.å¿«é€Ÿå“åº”é—®é¢˜"
            }
            answer = "æˆ‘ä¸»è¦ä¸“æ³¨äºæ•°æ®åˆ†æå’Œä¸šåŠ¡å»ºè®®ã€‚è¯·å…·ä½“æè¿°æ‚¨çš„é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›æœ‰é’ˆå¯¹æ€§çš„å»ºè®®ã€‚"
            for key in qa_pairs:
                if key in question:
                    answer = qa_pairs[key]
                    break

            st.info(f"**AIå›ç­”**: {answer}")
if 'analyze' not in st.session_state:
    st.session_state.analyze = False
if 'dataset_type' not in st.session_state:
    st.session_state.dataset_type = "é”€å”®æ•°æ®"

if __name__ == "__main__":
    main()